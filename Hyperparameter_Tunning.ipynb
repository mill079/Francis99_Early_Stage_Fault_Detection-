{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddf4eae-6481-465c-bbaf-b1925d14dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecdc4c02-5c84-425f-83ae-65b4bc67466c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIN1</th>\n",
       "      <th>PTC</th>\n",
       "      <th>PDT1</th>\n",
       "      <th>PDT2</th>\n",
       "      <th>PGV1</th>\n",
       "      <th>PGV2</th>\n",
       "      <th>PGV3</th>\n",
       "      <th>PDT3</th>\n",
       "      <th>PDT4</th>\n",
       "      <th>Patm</th>\n",
       "      <th>...</th>\n",
       "      <th>FricTorque</th>\n",
       "      <th>Pin</th>\n",
       "      <th>Pdiff</th>\n",
       "      <th>GV</th>\n",
       "      <th>AGV</th>\n",
       "      <th>ATB1</th>\n",
       "      <th>ATB2</th>\n",
       "      <th>Group</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.006195</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>0.024108</td>\n",
       "      <td>6.285425</td>\n",
       "      <td>...</td>\n",
       "      <td>1.246962</td>\n",
       "      <td>6.118898</td>\n",
       "      <td>6.649683</td>\n",
       "      <td>2.636216</td>\n",
       "      <td>0.297385</td>\n",
       "      <td>-0.163528</td>\n",
       "      <td>0.224599</td>\n",
       "      <td>DPL</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.020705</td>\n",
       "      <td>0.022757</td>\n",
       "      <td>6.291337</td>\n",
       "      <td>...</td>\n",
       "      <td>1.250575</td>\n",
       "      <td>6.142219</td>\n",
       "      <td>6.677930</td>\n",
       "      <td>2.635310</td>\n",
       "      <td>0.205243</td>\n",
       "      <td>-0.051941</td>\n",
       "      <td>0.307536</td>\n",
       "      <td>DPL</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.006524</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.021536</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>6.287724</td>\n",
       "      <td>...</td>\n",
       "      <td>1.245649</td>\n",
       "      <td>6.096892</td>\n",
       "      <td>6.639173</td>\n",
       "      <td>2.634754</td>\n",
       "      <td>0.124694</td>\n",
       "      <td>-0.024502</td>\n",
       "      <td>0.252041</td>\n",
       "      <td>DPL</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.021012</td>\n",
       "      <td>0.020271</td>\n",
       "      <td>6.283783</td>\n",
       "      <td>...</td>\n",
       "      <td>1.266670</td>\n",
       "      <td>6.125139</td>\n",
       "      <td>6.676617</td>\n",
       "      <td>2.634428</td>\n",
       "      <td>0.108219</td>\n",
       "      <td>-0.042185</td>\n",
       "      <td>0.274605</td>\n",
       "      <td>DPL</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002865</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.006531</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.019912</td>\n",
       "      <td>0.018715</td>\n",
       "      <td>6.288381</td>\n",
       "      <td>...</td>\n",
       "      <td>1.247619</td>\n",
       "      <td>6.032514</td>\n",
       "      <td>6.704535</td>\n",
       "      <td>2.634260</td>\n",
       "      <td>0.229651</td>\n",
       "      <td>-0.048283</td>\n",
       "      <td>0.203255</td>\n",
       "      <td>DPL</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13823995</th>\n",
       "      <td>0.002673</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>-0.006264</td>\n",
       "      <td>6.318599</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142187</td>\n",
       "      <td>5.881754</td>\n",
       "      <td>6.534067</td>\n",
       "      <td>4.384009</td>\n",
       "      <td>0.244296</td>\n",
       "      <td>0.208429</td>\n",
       "      <td>0.197766</td>\n",
       "      <td>FL</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13823996</th>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>0.022708</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>6.314329</td>\n",
       "      <td>...</td>\n",
       "      <td>1.134304</td>\n",
       "      <td>5.889965</td>\n",
       "      <td>6.556730</td>\n",
       "      <td>4.383941</td>\n",
       "      <td>0.122864</td>\n",
       "      <td>0.210258</td>\n",
       "      <td>0.222160</td>\n",
       "      <td>FL</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13823997</th>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.027942</td>\n",
       "      <td>-0.002138</td>\n",
       "      <td>6.316629</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127078</td>\n",
       "      <td>5.876498</td>\n",
       "      <td>6.520928</td>\n",
       "      <td>4.383734</td>\n",
       "      <td>0.261382</td>\n",
       "      <td>0.145623</td>\n",
       "      <td>0.202035</td>\n",
       "      <td>FL</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13823998</th>\n",
       "      <td>0.002670</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.006827</td>\n",
       "      <td>0.026696</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>6.320242</td>\n",
       "      <td>...</td>\n",
       "      <td>1.135289</td>\n",
       "      <td>5.878797</td>\n",
       "      <td>6.571511</td>\n",
       "      <td>4.383563</td>\n",
       "      <td>0.193038</td>\n",
       "      <td>0.041963</td>\n",
       "      <td>0.208134</td>\n",
       "      <td>FL</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13823999</th>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.006499</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>0.024260</td>\n",
       "      <td>-0.005821</td>\n",
       "      <td>6.321884</td>\n",
       "      <td>...</td>\n",
       "      <td>1.145143</td>\n",
       "      <td>5.872228</td>\n",
       "      <td>6.575780</td>\n",
       "      <td>4.383241</td>\n",
       "      <td>0.274807</td>\n",
       "      <td>0.105378</td>\n",
       "      <td>0.202035</td>\n",
       "      <td>FL</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13824000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PIN1       PTC      PDT1      PDT2      PGV1      PGV2  \\\n",
       "0         0.002862  0.001300  0.004675  0.004430  0.006501  0.005931   \n",
       "1         0.002862  0.001297  0.004674  0.004431  0.006519  0.005950   \n",
       "2         0.002862  0.001292  0.004673  0.004432  0.006524  0.005949   \n",
       "3         0.002863  0.001287  0.004673  0.004432  0.006537  0.005971   \n",
       "4         0.002865  0.001284  0.004673  0.004431  0.006531  0.005995   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "13823995  0.002673  0.001582  0.004092  0.003841  0.007138  0.006577   \n",
       "13823996  0.002672  0.001587  0.004089  0.003838  0.007111  0.006554   \n",
       "13823997  0.002671  0.001589  0.004089  0.003834  0.007081  0.006527   \n",
       "13823998  0.002670  0.001585  0.004087  0.003829  0.007069  0.006505   \n",
       "13823999  0.002671  0.001579  0.004087  0.003825  0.007050  0.006499   \n",
       "\n",
       "              PGV3      PDT3      PDT4      Patm  ...  FricTorque       Pin  \\\n",
       "0         0.006195  0.020413  0.024108  6.285425  ...    1.246962  6.118898   \n",
       "1         0.006197  0.020705  0.022757  6.291337  ...    1.250575  6.142219   \n",
       "2         0.006208  0.021536  0.021985  6.287724  ...    1.245649  6.096892   \n",
       "3         0.006211  0.021012  0.020271  6.283783  ...    1.266670  6.125139   \n",
       "4         0.006229  0.019912  0.018715  6.288381  ...    1.247619  6.032514   \n",
       "...            ...       ...       ...       ...  ...         ...       ...   \n",
       "13823995  0.006932  0.021125 -0.006264  6.318599  ...    1.142187  5.881754   \n",
       "13823996  0.006877  0.022708 -0.005751  6.314329  ...    1.134304  5.889965   \n",
       "13823997  0.006842  0.027942 -0.002138  6.316629  ...    1.127078  5.876498   \n",
       "13823998  0.006827  0.026696 -0.002301  6.320242  ...    1.135289  5.878797   \n",
       "13823999  0.006802  0.024260 -0.005821  6.321884  ...    1.145143  5.872228   \n",
       "\n",
       "             Pdiff        GV       AGV      ATB1      ATB2  Group  Stage  Head  \n",
       "0         6.649683  2.636216  0.297385 -0.163528  0.224599    DPL      1    24  \n",
       "1         6.677930  2.635310  0.205243 -0.051941  0.307536    DPL      1    24  \n",
       "2         6.639173  2.634754  0.124694 -0.024502  0.252041    DPL      1    24  \n",
       "3         6.676617  2.634428  0.108219 -0.042185  0.274605    DPL      1    24  \n",
       "4         6.704535  2.634260  0.229651 -0.048283  0.203255    DPL      1    24  \n",
       "...            ...       ...       ...       ...       ...    ...    ...   ...  \n",
       "13823995  6.534067  4.384009  0.244296  0.208429  0.197766     FL      9    24  \n",
       "13823996  6.556730  4.383941  0.122864  0.210258  0.222160     FL      9    24  \n",
       "13823997  6.520928  4.383734  0.261382  0.145623  0.202035     FL      9    24  \n",
       "13823998  6.571511  4.383563  0.193038  0.041963  0.208134     FL      9    24  \n",
       "13823999  6.575780  4.383241  0.274807  0.105378  0.202035     FL      9    24  \n",
       "\n",
       "[13824000 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(r\"E:\\Milan/time_series_dataset24.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1c03eb-54fd-4117-a5e3-078a2bcc3000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              PDT1      PGV2      PDT3      ATB1      ATB2  Stage\n",
      "0         0.004675  0.005931  0.020413 -0.163528  0.224599      1\n",
      "1         0.004674  0.005950  0.020705 -0.051941  0.307536      1\n",
      "2         0.004673  0.005949  0.021536 -0.024502  0.252041      1\n",
      "3         0.004673  0.005971  0.021012 -0.042185  0.274605      1\n",
      "4         0.004673  0.005995  0.019912 -0.048283  0.203255      1\n",
      "...            ...       ...       ...       ...       ...    ...\n",
      "13823995  0.004092  0.006577  0.021125  0.208429  0.197766      9\n",
      "13823996  0.004089  0.006554  0.022708  0.210258  0.222160      9\n",
      "13823997  0.004089  0.006527  0.027942  0.145623  0.202035      9\n",
      "13823998  0.004087  0.006505  0.026696  0.041963  0.208134      9\n",
      "13823999  0.004087  0.006499  0.024260  0.105378  0.202035      9\n",
      "\n",
      "[13824000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['PIN1','PTC','WTmp','Head','Patm','rpm','Speed','Flow','Thrust','GenTorque','FricTorque','Pin','Pdiff','GV','AGV','Group','PDT2','PGV1','PGV3','PDT4'], axis= 1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96417aec-5422-4fbf-843a-197f876c15a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ After windowing → Found stages and counts:\n",
      "Stage 1: 307195 samples\n",
      "Stage 2: 307200 samples\n",
      "Stage 3: 307200 samples\n",
      "Stage 4: 307200 samples\n",
      "Stage 5: 307200 samples\n",
      "Stage 6: 307200 samples\n",
      "Stage 7: 307200 samples\n",
      "Stage 8: 307200 samples\n",
      "Stage 9: 307199 samples\n",
      "\n",
      "✅ All stages present. Subsampling dataset to reduce size.\n",
      "\n",
      "✅ Final train/test stage distribution:\n",
      "Stage 1: Train = 122877, Test = 30720\n",
      "Stage 2: Train = 122880, Test = 30720\n",
      "Stage 3: Train = 122880, Test = 30720\n",
      "Stage 4: Train = 122880, Test = 30720\n",
      "Stage 5: Train = 122880, Test = 30720\n",
      "Stage 6: Train = 122880, Test = 30720\n",
      "Stage 7: Train = 122880, Test = 30720\n",
      "Stage 8: Train = 122880, Test = 30720\n",
      "Stage 9: Train = 122880, Test = 30720\n",
      "\n",
      "✅ Final dataset shapes:\n",
      "X_train shape: (1105917, 30, 5)\n",
      "X_test shape: (276480, 30, 5)\n",
      "y_train shape: (1105917,)\n",
      "y_test shape: (276480,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# --- Load Full Dataset ---\n",
    "features = ['PDT1', 'PGV2', 'PDT3', 'ATB1', 'ATB2']\n",
    "X = df[features].values\n",
    "y = df['Stage'].values\n",
    "\n",
    "# --- Normalization ---\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- Shift Labels to 0-based ---\n",
    "y = y - 1\n",
    "\n",
    "# --- Time Series Windowing ---\n",
    "window_size = 30\n",
    "stride = 5\n",
    "\n",
    "X_windows = []\n",
    "y_windows = []\n",
    "\n",
    "for i in range(0, len(X_scaled) - window_size, stride):\n",
    "    X_windows.append(X_scaled[i:i + window_size])\n",
    "    y_windows.append(y[i + window_size - 1])\n",
    "\n",
    "X_windows = np.array(X_windows)\n",
    "y_windows = np.array(y_windows)\n",
    "\n",
    "print(\"\\n✅ After windowing → Found stages and counts:\")\n",
    "unique, counts = np.unique(y_windows, return_counts=True)\n",
    "for stage, count in zip(unique + 1, counts):\n",
    "    print(f\"Stage {stage}: {count} samples\")\n",
    "\n",
    "# --- ✅ Subsample (Optional) Only if ALL 9 stages are present ---\n",
    "if len(unique) < 9:\n",
    "    print(\"\\n⚠️ Not all stages present. Skipping subsampling to preserve rare classes.\")\n",
    "else:\n",
    "    print(\"\\n✅ All stages present. Subsampling dataset to reduce size.\")\n",
    "    X_windows, _, y_windows, _ = train_test_split(\n",
    "        X_windows, y_windows,\n",
    "        test_size=0.5,\n",
    "        random_state=42,\n",
    "        stratify=y_windows\n",
    "    )\n",
    "\n",
    "# --- Train/Test Split (Stratify to balance stages) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_windows, y_windows,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_windows\n",
    ")\n",
    "\n",
    "# --- Final Stage Counts in Train/Test ---\n",
    "print(\"\\n✅ Final train/test stage distribution:\")\n",
    "train_stages, train_counts = np.unique(y_train, return_counts=True)\n",
    "test_stages, test_counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "for stage, train_c, test_c in zip(train_stages + 1, train_counts, test_counts):\n",
    "    print(f\"Stage {stage}: Train = {train_c}, Test = {test_c}\")\n",
    "\n",
    "# --- Output Final Shapes ---\n",
    "print(\"\\n✅ Final dataset shapes:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf7a8ce-047c-4699-b2c5-14e6654bf15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc9036f4-c989-4cf8-80c2-837c1d301e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras_tuner import HyperParameters\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_model(hp):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Conv1D Layer 1\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=hp.Int('conv1_filters', 64, 256, step=32),\n",
    "        kernel_size=hp.Choice('conv1_kernel', [3, 12]),\n",
    "        activation=hp.Choice('conv1_activation', ['relu', 'tanh']),\n",
    "        padding='same',\n",
    "        input_shape=(30, 5)\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # Conv1D Layer 2\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=hp.Int('conv2_filters', 64, 512, step=64),\n",
    "        kernel_size=hp.Choice('conv2_kernel', [3, 8]),\n",
    "        activation=hp.Choice('conv2_activation', ['relu', 'tanh']),\n",
    "        padding='same'\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # Conv1D Layer 3\n",
    "    model.add(layers.Conv1D(\n",
    "        filters=hp.Int('conv3_filters', 64, 512, step=64),\n",
    "        kernel_size=hp.Choice('conv3_kernel', [3, 5]),\n",
    "        activation=hp.Choice('conv3_activation', ['relu', 'tanh']),\n",
    "        padding='same'\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # LSTM Layer 1\n",
    "    model.add(layers.LSTM(\n",
    "        units=hp.Int('lstm1_units', 32, 128, step=32),\n",
    "        return_sequences=True,\n",
    "        dropout=hp.Float('lstm1_dropout', 0.0, 0.5, step=0.1)\n",
    "    ))\n",
    "\n",
    "    # LSTM Layer 2\n",
    "    model.add(layers.LSTM(\n",
    "        units=hp.Int('lstm2_units', 32, 128, step=32),\n",
    "        return_sequences=False,\n",
    "        dropout=hp.Float('lstm2_dropout', 0.0, 0.5, step=0.1)\n",
    "    ))\n",
    "\n",
    "    # Dense Layer 1\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('dense1_units', 64, 256, step=64),\n",
    "        activation=hp.Choice('dense1_activation', ['relu', 'tanh'])\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Dense Layer 2\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('dense2_units', 32, 128, step=32),\n",
    "        activation=hp.Choice('dense2_activation', ['relu', 'tanh'])\n",
    "    ))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(9, activation='softmax'))  # 9 classes\n",
    "\n",
    "    # Tunable Optimizer (Fixed Learning Rate)\n",
    "    optimizer_choice = hp.Choice('optimizer', ['adam', 'nadam', 'rmsprop'])\n",
    "    fixed_lr = 1e-3  # Fixed learning rate\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=fixed_lr)\n",
    "    elif optimizer_choice == 'nadam':\n",
    "        optimizer = tf.keras.optimizers.Nadam(learning_rate=fixed_lr)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=fixed_lr)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93474140-8688-4c95-bbc9-e879dabe19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TTL\\anaconda3\\envs\\ai-env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set up the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_tuner_results',\n",
    "    project_name='cnn_rnn_fault_detection'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a2b272-37d0-4d33-aefe-9b715ac4cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train with tuner\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf68cad6-8109-4b42-8b0b-95eb5b9b3fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [03h 21m 37s]\n",
      "val_accuracy: 0.7947365045547485\n",
      "\n",
      "Best val_accuracy So Far: 0.8114556074142456\n",
      "Total elapsed time: 1d 06h 45m 40s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    validation_split=0.2,\n",
    "    batch_size= 128,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd064bb5-3712-4e15-bbf8-dd9f692f4ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in my_tuner_results\\cnn_rnn_fault_detection\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 256\n",
      "conv1_kernel: 12\n",
      "conv1_activation: tanh\n",
      "conv2_filters: 320\n",
      "conv2_kernel: 3\n",
      "conv2_activation: relu\n",
      "conv3_filters: 256\n",
      "conv3_kernel: 5\n",
      "conv3_activation: relu\n",
      "lstm1_units: 96\n",
      "lstm1_dropout: 0.0\n",
      "lstm2_units: 128\n",
      "lstm2_dropout: 0.1\n",
      "dense1_units: 192\n",
      "dense1_activation: relu\n",
      "dense2_units: 96\n",
      "dense2_activation: tanh\n",
      "optimizer: nadam\n",
      "Score: 0.8114556074142456\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 96\n",
      "conv1_kernel: 3\n",
      "conv1_activation: relu\n",
      "conv2_filters: 448\n",
      "conv2_kernel: 8\n",
      "conv2_activation: tanh\n",
      "conv3_filters: 384\n",
      "conv3_kernel: 3\n",
      "conv3_activation: relu\n",
      "lstm1_units: 32\n",
      "lstm1_dropout: 0.0\n",
      "lstm2_units: 64\n",
      "lstm2_dropout: 0.2\n",
      "dense1_units: 192\n",
      "dense1_activation: tanh\n",
      "dense2_units: 32\n",
      "dense2_activation: relu\n",
      "optimizer: nadam\n",
      "Score: 0.7947365045547485\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 192\n",
      "conv1_kernel: 3\n",
      "conv1_activation: tanh\n",
      "conv2_filters: 512\n",
      "conv2_kernel: 3\n",
      "conv2_activation: relu\n",
      "conv3_filters: 320\n",
      "conv3_kernel: 3\n",
      "conv3_activation: relu\n",
      "lstm1_units: 128\n",
      "lstm1_dropout: 0.30000000000000004\n",
      "lstm2_units: 96\n",
      "lstm2_dropout: 0.1\n",
      "dense1_units: 128\n",
      "dense1_activation: tanh\n",
      "dense2_units: 32\n",
      "dense2_activation: tanh\n",
      "optimizer: rmsprop\n",
      "Score: 0.7932626008987427\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 256\n",
      "conv1_kernel: 3\n",
      "conv1_activation: tanh\n",
      "conv2_filters: 256\n",
      "conv2_kernel: 8\n",
      "conv2_activation: tanh\n",
      "conv3_filters: 64\n",
      "conv3_kernel: 5\n",
      "conv3_activation: relu\n",
      "lstm1_units: 128\n",
      "lstm1_dropout: 0.1\n",
      "lstm2_units: 128\n",
      "lstm2_dropout: 0.4\n",
      "dense1_units: 128\n",
      "dense1_activation: tanh\n",
      "dense2_units: 96\n",
      "dense2_activation: relu\n",
      "optimizer: nadam\n",
      "Score: 0.7896637916564941\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 256\n",
      "conv1_kernel: 3\n",
      "conv1_activation: tanh\n",
      "conv2_filters: 192\n",
      "conv2_kernel: 8\n",
      "conv2_activation: tanh\n",
      "conv3_filters: 256\n",
      "conv3_kernel: 5\n",
      "conv3_activation: relu\n",
      "lstm1_units: 32\n",
      "lstm1_dropout: 0.1\n",
      "lstm2_units: 32\n",
      "lstm2_dropout: 0.0\n",
      "dense1_units: 64\n",
      "dense1_activation: relu\n",
      "dense2_units: 32\n",
      "dense2_activation: tanh\n",
      "optimizer: rmsprop\n",
      "Score: 0.7823486328125\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 192\n",
      "conv1_kernel: 12\n",
      "conv1_activation: tanh\n",
      "conv2_filters: 448\n",
      "conv2_kernel: 8\n",
      "conv2_activation: relu\n",
      "conv3_filters: 64\n",
      "conv3_kernel: 5\n",
      "conv3_activation: tanh\n",
      "lstm1_units: 32\n",
      "lstm1_dropout: 0.0\n",
      "lstm2_units: 32\n",
      "lstm2_dropout: 0.30000000000000004\n",
      "dense1_units: 64\n",
      "dense1_activation: relu\n",
      "dense2_units: 96\n",
      "dense2_activation: relu\n",
      "optimizer: nadam\n",
      "Score: 0.7810962796211243\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 224\n",
      "conv1_kernel: 12\n",
      "conv1_activation: relu\n",
      "conv2_filters: 384\n",
      "conv2_kernel: 8\n",
      "conv2_activation: tanh\n",
      "conv3_filters: 256\n",
      "conv3_kernel: 5\n",
      "conv3_activation: relu\n",
      "lstm1_units: 96\n",
      "lstm1_dropout: 0.30000000000000004\n",
      "lstm2_units: 128\n",
      "lstm2_dropout: 0.4\n",
      "dense1_units: 128\n",
      "dense1_activation: tanh\n",
      "dense2_units: 64\n",
      "dense2_activation: relu\n",
      "optimizer: rmsprop\n",
      "Score: 0.7784830927848816\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 192\n",
      "conv1_kernel: 12\n",
      "conv1_activation: tanh\n",
      "conv2_filters: 192\n",
      "conv2_kernel: 8\n",
      "conv2_activation: tanh\n",
      "conv3_filters: 320\n",
      "conv3_kernel: 3\n",
      "conv3_activation: tanh\n",
      "lstm1_units: 128\n",
      "lstm1_dropout: 0.30000000000000004\n",
      "lstm2_units: 96\n",
      "lstm2_dropout: 0.30000000000000004\n",
      "dense1_units: 128\n",
      "dense1_activation: relu\n",
      "dense2_units: 96\n",
      "dense2_activation: relu\n",
      "optimizer: rmsprop\n",
      "Score: 0.7705891728401184\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 224\n",
      "conv1_kernel: 3\n",
      "conv1_activation: relu\n",
      "conv2_filters: 512\n",
      "conv2_kernel: 3\n",
      "conv2_activation: relu\n",
      "conv3_filters: 448\n",
      "conv3_kernel: 3\n",
      "conv3_activation: tanh\n",
      "lstm1_units: 128\n",
      "lstm1_dropout: 0.0\n",
      "lstm2_units: 96\n",
      "lstm2_dropout: 0.4\n",
      "dense1_units: 128\n",
      "dense1_activation: relu\n",
      "dense2_units: 96\n",
      "dense2_activation: relu\n",
      "optimizer: nadam\n",
      "Score: 0.7673203945159912\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "conv1_filters: 192\n",
      "conv1_kernel: 3\n",
      "conv1_activation: relu\n",
      "conv2_filters: 384\n",
      "conv2_kernel: 3\n",
      "conv2_activation: tanh\n",
      "conv3_filters: 64\n",
      "conv3_kernel: 3\n",
      "conv3_activation: relu\n",
      "lstm1_units: 128\n",
      "lstm1_dropout: 0.4\n",
      "lstm2_units: 128\n",
      "lstm2_dropout: 0.2\n",
      "dense1_units: 256\n",
      "dense1_activation: tanh\n",
      "dense2_units: 64\n",
      "dense2_activation: relu\n",
      "optimizer: rmsprop\n",
      "Score: 0.7611852288246155\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e94318-3bbb-4bfd-a598-92cf0ed01623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TTL\\anaconda3\\envs\\ai-env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best Hyperparameters Found:\n",
      "conv1_filters: 256\n",
      "conv1_kernel: 12\n",
      "conv1_activation: tanh\n",
      "conv2_filters: 320\n",
      "conv2_kernel: 3\n",
      "conv2_activation: relu\n",
      "conv3_filters: 256\n",
      "conv3_kernel: 5\n",
      "conv3_activation: relu\n",
      "lstm1_units: 96\n",
      "lstm1_dropout: 0.0\n",
      "lstm2_units: 128\n",
      "lstm2_dropout: 0.1\n",
      "dense1_units: 192\n",
      "dense1_activation: relu\n",
      "dense2_units: 96\n",
      "dense2_activation: tanh\n",
      "optimizer: nadam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TTL\\anaconda3\\envs\\ai-env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'nadam', because it has 2 variables whereas the saved optimizer has 59 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "\n",
    "print(\"\\n✅ Best Hyperparameters Found:\")\n",
    "for param in best_hps.values:\n",
    "    print(f\"{param}: {best_hps.get(param)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e88f1-2d7a-4271-a3cd-68bcceda0fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai-env]",
   "language": "python",
   "name": "conda-env-ai-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
